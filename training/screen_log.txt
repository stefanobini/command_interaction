Loaded </home/sbini_loc/command_interaction/training/settings/FELICE_conf.py> as configuration file.
CUDA acceleration available on <5> devices: <[0, 1, 2, 3, 4]>
The current device is <0>, you select device <2>
Global seed set to 2
The TensorBoard logggers will be saved in <lightning_logs/FELICE/demo3/eng/resnet8/UniCL_PEM_v2_reduced_precision>.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]

   | Name    | Type             | Params
----------------------------------------------
0  | conv0   | Conv2d           | 405   
1  | pool    | AvgPool2d        | 0     
2  | bn1     | BatchNorm2d      | 0     
3  | conv1   | Conv2d           | 18.2 K
4  | bn2     | BatchNorm2d      | 0     
5  | conv2   | Conv2d           | 18.2 K
6  | bn3     | BatchNorm2d      | 0     
7  | conv3   | Conv2d           | 18.2 K
8  | bn4     | BatchNorm2d      | 0     
9  | conv4   | Conv2d           | 18.2 K
10 | bn5     | BatchNorm2d      | 0     
11 | conv5   | Conv2d           | 18.2 K
12 | bn6     | BatchNorm2d      | 0     
13 | conv6   | Conv2d           | 18.2 K
14 | output  | Linear           | 230   
15 | softmax | Softmax          | 0     
16 | loss_fn | CrossEntropyLoss | 0     
----------------------------------------------
109 K     Trainable params
0         Non-trainable params
109 K     Total params
0.440     Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/153 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/153 [00:00<?, ?it/s] Epoch 0:   1%|          | 1/153 [00:37<1:35:38, 37.75s/it]Epoch 0:   1%|          | 1/153 [00:37<1:35:38, 37.75s/it, v_num=sion]Epoch 0:   1%|▏         | 2/153 [00:37<47:32, 18.89s/it, v_num=sion]  Epoch 0:   1%|▏         | 2/153 [00:37<47:33, 18.89s/it, v_num=sion]Epoch 0:   2%|▏         | 3/153 [00:40<34:00, 13.60s/it, v_num=sion]Epoch 0:   2%|▏         | 3/153 [00:40<34:00, 13.60s/it, v_num=sion]Epoch 0:   3%|▎         | 4/153 [00:40<25:21, 10.21s/it, v_num=sion]Epoch 0:   3%|▎         | 4/153 [00:40<25:21, 10.21s/it, v_num=sion]Epoch 0:   3%|▎         | 5/153 [00:40<20:10,  8.18s/it, v_num=sion]Epoch 0:   3%|▎         | 5/153 [00:40<20:10,  8.18s/it, v_num=sion]Epoch 0:   4%|▍         | 6/153 [00:40<16:43,  6.82s/it, v_num=sion]Epoch 0:   4%|▍         | 6/153 [00:40<16:43,  6.82s/it, v_num=sion]Epoch 0:   5%|▍         | 7/153 [00:40<14:14,  5.85s/it, v_num=sion]Epoch 0:   5%|▍         | 7/153 [00:40<14:14,  5.85s/it, v_num=sion]Epoch 0:   5%|▌         | 8/153 [00:42<12:52,  5.32s/it, v_num=sion]Epoch 0:   5%|▌         | 8/153 [00:42<12:52,  5.32s/it, v_num=sion]Epoch 0:   6%|▌         | 9/153 [00:42<11:22,  4.74s/it, v_num=sion]Epoch 0:   6%|▌         | 9/153 [00:42<11:22,  4.74s/it, v_num=sion]Epoch 0:   7%|▋         | 10/153 [00:42<10:10,  4.27s/it, v_num=sion]Epoch 0:   7%|▋         | 10/153 [00:42<10:10,  4.27s/it, v_num=sion]Epoch 0:   7%|▋         | 11/153 [00:43<09:18,  3.93s/it, v_num=sion]Epoch 0:   7%|▋         | 11/153 [00:43<09:18,  3.93s/it, v_num=sion]Epoch 0:   8%|▊         | 12/153 [04:02<47:33, 20.24s/it, v_num=sion]Epoch 0:   8%|▊         | 12/153 [04:02<47:33, 20.24s/it, v_num=sion]Epoch 0:   8%|▊         | 13/153 [04:03<43:37, 18.70s/it, v_num=sion]Epoch 0:   8%|▊         | 13/153 [04:03<43:37, 18.70s/it, v_num=sion]Epoch 0:   9%|▉         | 14/153 [04:03<40:13, 17.36s/it, v_num=sion]Epoch 0:   9%|▉         | 14/153 [04:03<40:13, 17.36s/it, v_num=sion]Epoch 0:  10%|▉         | 15/153 [04:03<37:16, 16.21s/it, v_num=sion]Epoch 0:  10%|▉         | 15/153 [04:03<37:16, 16.21s/it, v_num=sion]Epoch 0:  10%|█         | 16/153 [04:03<34:42, 15.20s/it, v_num=sion]Epoch 0:  10%|█         | 16/153 [04:03<34:42, 15.20s/it, v_num=sion]